{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ffd1f1-0eaf-4618-93e9-fbc904478288",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import geopandas\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from osgeo import ogr,gdal\n",
    "import numpy \n",
    "from shapely.wkb import loads\n",
    "import pygeos\n",
    "import matplotlib.pyplot as plt\n",
    "import openpyxl\n",
    "import itertools\n",
    "import networkx as nx\n",
    "from simplify import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d5278f-006e-4187-94a8-c00a3757f8e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gdal.SetConfigOption(\"OSM_CONFIG_FILE\", \"osmconf.ini\")\n",
    "\n",
    "# Define a helper function to generate pairs of consecutive elements in a list\n",
    "def pairwise(iterable):\n",
    "    \"s -> (s0, s1), (s1, s2), (s2, s3), ...\"\n",
    "    a, b = itertools.tee(iterable)\n",
    "    next(b, None)\n",
    "    return zip(a, b)\n",
    "\n",
    "\n",
    "# Define a helper function to generate permutations\n",
    "def permutations(iterable, r=None):\n",
    "   # permutations('ABCD', 2) --> AB AC AD BA BC BD CA CB CD DA DB DC\n",
    "    # permutations(range(3)) --> 012 021 102 120 201 210\n",
    "    pool = tuple(iterable)\n",
    "    n = len(pool)\n",
    "    r = n if r is None else r\n",
    "    if r > n:\n",
    "        return\n",
    "    indices = list(range(n))\n",
    "    cycles = list(range(n, n-r, -1))\n",
    "    yield tuple(pool[i] for i in indices[:r])\n",
    "    while n:\n",
    "        for i in reversed(range(r)):\n",
    "            cycles[i] -= 1\n",
    "            if cycles[i] == 0:\n",
    "                indices[i:] = indices[i+1:] + indices[i:i+1]\n",
    "                cycles[i] = n - i\n",
    "            else:\n",
    "                j = cycles[i]\n",
    "                indices[i], indices[-j] = indices[-j], indices[i]\n",
    "                yield tuple(pool[i] for i in indices[:r])\n",
    "                break\n",
    "        else:\n",
    "            return \n",
    "        \n",
    "        \n",
    "# Retrive data from OSM and get the geographic data of subway\n",
    "def query_b(geoType,keyCol,**valConstraint):\n",
    "    \"\"\"\n",
    "    This function builds an SQL query from the values passed to the retrieve() function.\n",
    "    Arguments:\n",
    "         *geoType* : Type of geometry (osm layer) to search for.\n",
    "         *keyCol* : A list of keys/columns that should be selected from the layer.\n",
    "         ***valConstraint* : A dictionary of constraints for the values. e.g. WHERE 'value'>20 or 'value'='constraint'\n",
    "    Returns:\n",
    "        *string: : a SQL query string.\n",
    "    \"\"\"\n",
    "    query = \"SELECT \" + \"osm_id\"\n",
    "    for a in keyCol: query+= \",\"+ a  \n",
    "    query += \" FROM \" + geoType + \" WHERE \"\n",
    "    # If there are values in the dictionary, add constraint clauses\n",
    "    if valConstraint: \n",
    "        for a in [*valConstraint]:\n",
    "            # For each value of the key, add the constraint\n",
    "            for b in valConstraint[a]: query += a + b\n",
    "        query+= \" AND \"\n",
    "    # Always ensures the first key/col provided is not Null.\n",
    "    query+= \"\"+str(keyCol[0]) +\" IS NOT NULL\" \n",
    "    return query \n",
    "\n",
    "def retrieve(osm_path,geoType,keyCol,**valConstraint):\n",
    "    \"\"\"\n",
    "    Function to extract specified geometry and keys/values from OpenStreetMap\n",
    "    Arguments:\n",
    "        *osm_path* : file path to the .osm.pbf file of the region \n",
    "        for which we want to do the analysis.     \n",
    "        *geoType* : Type of Geometry to retrieve. e.g. lines, multipolygons, etc.\n",
    "        *keyCol* : These keys will be returned as columns in the dataframe.\n",
    "        ***valConstraint: A dictionary specifiying the value constraints.  \n",
    "        A key can have multiple values (as a list) for more than one constraint for key/value.  \n",
    "    Returns:\n",
    "        *GeoDataFrame* : a geopandas GeoDataFrame with all columns, geometries, and constraints specified.    \n",
    "    \"\"\"\n",
    "    driver=ogr.GetDriverByName('OSM')\n",
    "    data = driver.Open(osm_path)\n",
    "    query = query_b(geoType,keyCol,**valConstraint)\n",
    "    sql_lyr = data.ExecuteSQL(query)\n",
    "    features =[]\n",
    "    # cl = columns \n",
    "    cl = ['osm_id']\n",
    "    \n",
    "    \n",
    "    for a in keyCol: cl.append(a)\n",
    "    if data is not None:\n",
    "        for feature in sql_lyr:\n",
    "            try:\n",
    "                if feature.GetField(keyCol[0]) is not None:\n",
    "                    pygeos_geo = pygeos.from_wkt(feature.geometry().ExportToWkt())\n",
    "                    if pygeos_geo is None:\n",
    "                        continue\n",
    "                    # field will become a row in the dataframe.\n",
    "                    field = []\n",
    "                    for i in cl: field.append(feature.GetField(i))\n",
    "                    field.append(pygeos_geo)   \n",
    "                    features.append(field)\n",
    "            except:\n",
    "                print(\"WARNING: skipped OSM feature\")\n",
    "      \n",
    "    cl.append('geometry')                   \n",
    "    if len(features) > 0:\n",
    "        return geopandas.GeoDataFrame(features,columns=cl) #,crs={'init': 'epsg:4326'}\n",
    "    else:\n",
    "        print(\"WARNING: No features or No Memory. returning empty GeoDataFrame\") \n",
    "        return geopandas.GeoDataFrame(columns=['osm_id','geometry']) #,crs={'init': 'epsg:4326'}\n",
    "    \n",
    "def railway(osm_path):\n",
    "    \"\"\"\n",
    "    Function to extract railway linestrings from OpenStreetMap\n",
    "    Arguments:\n",
    "        *osm_path* : file path to the .osm.pbf file of the region \n",
    "        for which we want to do the analysis.       \n",
    "    Returns:\n",
    "        *GeoDataFrame* : a geopandas GeoDataFrame with all unique land-use polygons.\n",
    "    \"\"\" \n",
    "    return retrieve(osm_path,'lines',['railway','service'])\n",
    "\n",
    "def subway_network(osm_path):\n",
    "    \"\"\"\n",
    "    Extract subway network information from an OpenStreetMap XML file.\n",
    "\n",
    "    Args:\n",
    "    - osm_path: a string representing the path to the OpenStreetMap XML file\n",
    "\n",
    "    Returns:\n",
    "    - a pandas DataFrame containing information about subway railways in the OpenStreetMap data\n",
    "\n",
    "    Example:\n",
    "    >>> import pandas as pd\n",
    "    >>> osm_path = 'path/to/osm/file.xml'\n",
    "    >>> subway_network = subway_network(osm_path)\n",
    "    >>> print(subway_network.head())\n",
    "          osmid        name        railway  ...    ref tunnel        geometry\n",
    "    1234  1234    Line 1    subway   ...  M1    yes  LINESTRING (0.0 0.0, 1.0 1.0)\n",
    "    5678  5678    Line 2    subway   ...  M2    yes  LINESTRING (1.0 1.0, 2.0 2.0)\n",
    "\n",
    "    Note: This function requires the osmnx library to be installed and OpenStreetMap data with railway information to be available.\n",
    "    \"\"\"\n",
    "    # Use the osmnx library to extract railway information from the OpenStreetMap data\n",
    "    df_railway = railway(osm_path)\n",
    "    \n",
    "    # Filter the DataFrame to include only subway railways\n",
    "    subway = df_railway.loc[df_railway.railway == 'subway']\n",
    "    \n",
    "    return subway\n",
    "\n",
    "\n",
    "def tram_network(osm_path):\n",
    "    \n",
    "    df_railway = railway(osm_path)\n",
    "    \n",
    "    tram = df_railway.loc[df_railway.railway == 'tram']\n",
    "    return tram\n",
    "    \n",
    "\n",
    "# Pre-processing the geographic data of the subway network to obtain 'edges' and 'nodes'\n",
    "def prepare_network(subway):\n",
    "    \"\"\"\n",
    "    Prepare a subway network represented as a GeoDataFrame of LineString objects for routing.\n",
    "\n",
    "    Args:\n",
    "    - subway: a GeoDataFrame representing the subway network, with 'geometry' column containing LineString objects\n",
    "    \n",
    "    Returns:\n",
    "    - a tuple of two DataFrames representing the edges and nodes of the prepared network\n",
    "\n",
    "    Example:\n",
    "    >>> import geopandas\n",
    "    >>> subway = geopandas.read_file('subway.shp')\n",
    "    >>> edges, nodes = prepare_network(subway)\n",
    "\n",
    "    Note: This function requires the PyGEOS, NetworkX, and Pandas libraries to be installed.\n",
    "    \"\"\"\n",
    "    # Convert the subway GeoDataFrame's 'geometry' column from Shapely objects to PyGEOS objects\n",
    "    df_subway = pd.DataFrame(subway.copy())\n",
    "    df_subway.geometry = pygeos.from_shapely(df_subway.geometry)\n",
    "    \n",
    "    # Build a Network object from the subway edges\n",
    "    net = Network(edges=df_subway)\n",
    "\n",
    "    # Add endpoints to the network where edges don't intersect\n",
    "    net = add_endpoints(net)\n",
    "\n",
    "    # Split edges at new endpoints\n",
    "    net = split_edges_at_nodes(net)\n",
    "\n",
    "    # Add new endpoints where edges were split\n",
    "    net = add_endpoints(net)\n",
    "\n",
    "    # Assign unique IDs to nodes and edges\n",
    "    net = add_ids(net)\n",
    "\n",
    "    # Add missing topology information to the network's edges\n",
    "    net = add_topology(net)    \n",
    "\n",
    "    # Calculate the degree of each node in the network\n",
    "    net.nodes['degree'] = calculate_degree(net)\n",
    "\n",
    "    # Merge edges with a degree of 2\n",
    "    net = merge_edges(net)\n",
    "\n",
    "    # Drop duplicate edges\n",
    "    net.edges = drop_duplicate_geometries(net.edges, keep='first') \n",
    "\n",
    "    # Reset node and edge IDs after fixing topology and merging edges\n",
    "    net = reset_ids(net) \n",
    "\n",
    "    # Add edge distances\n",
    "    net = add_distances(net)\n",
    "\n",
    "    # Merge any MultiLineString edges\n",
    "    net = merge_multilinestrings(net)\n",
    "\n",
    "    # Add travel time for each edge based on distance and average speed\n",
    "    net = add_travel_time(net)\n",
    "    \n",
    "    # Return the edges and nodes of the prepared network\n",
    "    return net.edges, net.nodes\n",
    "\n",
    "def expand_edges(edges):\n",
    "    \"\"\"\n",
    "    Expand a DataFrame of edges into a format that can be used with network analysis algorithms.\n",
    "\n",
    "    Args:\n",
    "    - edges: a DataFrame containing edges with columns 'from_id', 'to_id', and 'distance'\n",
    "\n",
    "    Returns:\n",
    "    - a DataFrame containing expanded edges with columns 'from_id', 'to_id', 'distance', 'dis_weights', 'to_from', and 'from_to'\n",
    "\n",
    "    Example:\n",
    "    >>> edges = pd.DataFrame({'from_id': [0, 0, 1], 'to_id': [1, 2, 2], 'distance': [1.5, 3.2, 2.8]})\n",
    "    >>> expand_edges(edges)\n",
    "      from_id  to_id  distance  dis_eights  to_from  from_to\n",
    "    0       0      1       1.5        1  (0, 1)  (1, 0)\n",
    "    1       0      2       3.2        3  (0, 2)  (2, 0)\n",
    "    2       1      2       2.8        2  (1, 2)  (2, 1)\n",
    "\n",
    "    Notes:\n",
    "    - The 'dis_weights' column is created by rounding the 'distance' column to the nearest integer.\n",
    "    - The 'to_from' and 'from_to' columns are created to facilitate conversion between edge formats.\n",
    "    \"\"\"\n",
    "    # Round the distance to the nearest integer and store it in a new column 'dis_weights'\n",
    "    edges['dis_weights'] = edges['distance'].astype(int)\n",
    "\n",
    "    # Create 'to_from' and 'from_to' columns to facilitate conversion between edge formats\n",
    "    edges['to_from'] = list(zip(edges.from_id, edges.to_id))\n",
    "    edges['from_to'] = list(zip(edges.to_id, edges.from_id))\n",
    "\n",
    "    # Return the expanded edges DataFrame\n",
    "    return edges\n",
    "\n",
    "\n",
    "# Create a base Graph object as the basic topology network with 'edges' and 'nodes'\n",
    "def create_ground_graph(edges, nodes):\n",
    "    \"\"\"\n",
    "    Create a networkx Graph object representing a ground transportation network.\n",
    "\n",
    "    Args:\n",
    "    - edges: a pandas DataFrame containing edges in the network, with columns 'from_id', 'to_id', and 'dis_weights'\n",
    "    - nodes: a GeoDataFrame containing nodes in the network, with a 'geometry' column representing their coordinates as PyGEOS Point objects\n",
    "    \n",
    "    Returns:\n",
    "    - a networkx Graph object representing the ground transportation network\n",
    "\n",
    "    Example:\n",
    "    >>> import pandas as pd\n",
    "    >>> import geopandas as gpd\n",
    "    >>> import networkx as nx\n",
    "    >>> edges = pd.read_csv('edges.csv')\n",
    "    >>> nodes = gpd.read_file('nodes.shp')\n",
    "    >>> G = create_ground_graph(edges, nodes)\n",
    "\n",
    "    Note: This function requires the pandas, geopandas, and networkx libraries to be installed.\n",
    "    \"\"\"\n",
    "    # Extract the edges from the input DataFrame and create a list of tuples with dis_weights\n",
    "    od = edges[['from_id', 'to_id', 'dis_weights']]\n",
    "    edges_list = []\n",
    "    for i, row in od.iterrows():\n",
    "        weight_dict = {\"weight\": row[2]}\n",
    "        tuple_row = (row[0], row[1], weight_dict)\n",
    "        edges_list.append(tuple_row)\n",
    "    \n",
    "    # Extract the nodes from the input GeoDataFrame and create a list of node IDs\n",
    "    nodes_list = nodes.iloc[:,2].tolist()\n",
    "    \n",
    "    # Create an empty Graph object and add the nodes and edges\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(nodes_list)\n",
    "    G.add_edges_from(edges_list)\n",
    "    \n",
    "    return G\n",
    "\n",
    "\n",
    "# Create coordinates of random start and end points in the research area\n",
    "def create_grid(bbox, height):\n",
    "    \"\"\"Create a vector-based grid.\n",
    "\n",
    "    Args:\n",
    "        bbox: A tuple or list containing the bounding box coordinates as (xmin, ymin, xmax, ymax).\n",
    "        height: The size of the grid.\n",
    "\n",
    "    Returns:\n",
    "        A PyGEOS polygon object representing the grid.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Set xmin, ymin, xmax, and ymax of the grid\n",
    "    xmin, ymin = pygeos.total_bounds(bbox)[0], pygeos.total_bounds(bbox)[1]\n",
    "    xmax, ymax = pygeos.total_bounds(bbox)[2], pygeos.total_bounds(bbox)[3]\n",
    "    \n",
    "    # Estimate total rows and columns\n",
    "    rows = int(np.ceil((ymax-ymin) / height))\n",
    "    cols = int(np.ceil((xmax-xmin) / height))\n",
    "\n",
    "    # Set corner points\n",
    "    x_left_origin = xmin\n",
    "    x_right_origin = xmin + height\n",
    "    y_top_origin = ymax\n",
    "    y_bottom_origin = ymax - height\n",
    "\n",
    "    # Create actual grid\n",
    "    res_geoms = []\n",
    "    for countcols in range(cols):\n",
    "        y_top = y_top_origin\n",
    "        y_bottom = y_bottom_origin\n",
    "        for countrows in range(rows):\n",
    "            # Append the four corner points of each cell to the list\n",
    "            res_geoms.append((\n",
    "                ((x_left_origin, y_top), (x_right_origin, y_top),\n",
    "                 (x_right_origin, y_bottom), (x_left_origin, y_bottom)\n",
    "                )))\n",
    "            y_top = y_top - height\n",
    "            y_bottom = y_bottom - height\n",
    "        x_left_origin = x_left_origin + height\n",
    "        x_right_origin = x_right_origin + height\n",
    "\n",
    "    # Convert the list of corner points into a PyGEOS polygon object\n",
    "    return pygeos.polygons(res_geoms)\n",
    "\n",
    "def coordinates_pairs(create_grid):\n",
    "    \"\"\"\n",
    "    Generates a pandas DataFrame of all possible coordinate pairs between grid center points.\n",
    "\n",
    "    Args:\n",
    "    - create_grid: a GeoDataFrame containing the grid polygons, with a 'geometry' column representing their coordinates as PyGEOS Polygon objects.\n",
    "\n",
    "    Returns:\n",
    "    - A pandas DataFrame containing all possible coordinate pairs as PyGEOS Point objects. \n",
    "    - The DataFrame has two columns: 's_coordinates' and 'e_coordinates', which represent the starting and ending coordinates of each pair, respectively.\n",
    "\n",
    "    Example:\n",
    "    >>> import geopandas as gpd\n",
    "    >>> import pandas as pd\n",
    "    >>> import pygeos\n",
    "    >>> import itertools\n",
    "    >>> create_grid = gpd.read_file('grid.shp')\n",
    "    >>> coord_pairs = coordinates_pairs(create_grid)\n",
    "\n",
    "    Note: This function requires the geopandas, pandas, pygeos, and itertools libraries to be installed.\n",
    "    \"\"\"\n",
    "    # Calculate the centroid of each grid polygon and store them in a new GeoDataFrame\n",
    "    grid_center_coordinates = gpd.GeoDataFrame(pygeos.centroid(create_grid.geometry.values),columns=['geometry'])\n",
    "    \n",
    "    # Create a new GeoDataFrame containing all possible pairs of coordinates from the grid centroids\n",
    "    coordinates_pairs = gpd.GeoDataFrame(itertools.permutations(grid_center_coordinates.geometry, 2), columns=['s_coordinates', 'e_coordinates'])\n",
    "    \n",
    "    # Convert the GeoDataFrame to a pandas DataFrame and return a copy of the DataFrame\n",
    "    return pd.DataFrame(coordinates_pairs.copy())\n",
    "\n",
    "\n",
    "# Define nearest nodes with real_world coordinates of start and end points, obtain the nearest id pairs of nodes \n",
    "def find_nearest_node(coordinate, nodes):\n",
    "    \"\"\"\n",
    "    Find the nearest node to a given coordinate or geometry in a GeoDataFrame of nodes.\n",
    "\n",
    "    Args:\n",
    "    - coordinate: a tuple of longitude and latitude (in decimal degrees) or a PyGEOS geometry object representing the location to search from\n",
    "    - nodes: a GeoDataFrame containing nodes with a 'geometry' column representing their coordinates as PyGEOS Point objects\n",
    "    \n",
    "    Returns:\n",
    "    - the id value of the nearest node to the input coordinate or geometry\n",
    "\n",
    "    Example:\n",
    "    >>> import geopandas\n",
    "    >>> from shapely.geometry import Point\n",
    "    >>> from pygeos import Geometry\n",
    "    >>> nodes = geopandas.read_file('nodes.shp')\n",
    "    >>> coordinate = (-122.3, 47.6)\n",
    "    >>> find_nearest_node(coordinate, nodes)\n",
    "    1234\n",
    "\n",
    "    Note: This function requires the PyGEOS and STRtree libraries to be installed.\n",
    "    \"\"\"\n",
    "    # Build an STRtree index of the nodes' geometries for efficient nearest-neighbor search\n",
    "    node_tree = pygeos.STRtree(nodes.geometry)\n",
    "   \n",
    "    # Find the nearest node to the input coordinate or geometry using the STRtree index\n",
    "    if isinstance(coordinate, tuple):\n",
    "        find_nearest = node_tree.nearest(pygeos.points(coordinate))\n",
    "    elif isinstance(coordinate, pygeos.lib.Geometry):\n",
    "        find_nearest = node_tree.nearest(coordinate)\n",
    "    \n",
    "    # Return the id value of the nearest node from the nodes GeoDataFrame\n",
    "    return int(nodes.iloc[find_nearest[1]]['id'])\n",
    "\n",
    "\n",
    "def id_pairs(coordinates_pairs, nodes):\n",
    "    \"\"\"\n",
    "    Map the start and end coordinates to the nearest nodes in a transportation network.\n",
    "\n",
    "    Args:\n",
    "    - coordinates_pairs: a pandas DataFrame containing start and end coordinates in the network, with columns 's_coordinates', 'e_coordinates'\n",
    "    - nodes: a GeoDataFrame containing nodes in the network, with a 'geometry' column representing their coordinates as PyGEOS Point objects\n",
    "\n",
    "    Returns:\n",
    "    - a pandas DataFrame containing the nearest node IDs for each start and end coordinate pair, with columns 's_id', 'e_id'\n",
    "\n",
    "    \"\"\"\n",
    "    # Initialize an empty DataFrame to store the start and end node IDs\n",
    "    id_pairs = pd.DataFrame(columns=['s_id','e_id'])\n",
    "    pairs_num = coordinates_pairs.shape[0]\n",
    "    \n",
    "    # For each start and end coordinate pair, find the nearest node in the network and store the node IDs in the DataFrame\n",
    "    for i in range(pairs_num):\n",
    "        s_coordinate = pygeos.points(coordinates_pairs.s_coordinates[i])\n",
    "        s_id = find_nearest_node(s_coordinate, nodes)\n",
    "        e_coordinate = pygeos.points(coordinates_pairs.e_coordinates[i])\n",
    "        e_id = find_nearest_node(e_coordinate, nodes)\n",
    "        id_pairs.loc[i] = [s_id,e_id]\n",
    "        \n",
    "    return id_pairs\n",
    "\n",
    "\n",
    "# Calculate the shorted path\n",
    "def shortest_path(G, start_point_id, end_point_id, edges, weight = \"weight\"):   # calculate the shortest path for one start_end_node id_pair\n",
    "    \"\"\"\n",
    "    Compute the shortest path between two nodes in a given graph, along with its length and the edges that belong to the path.\n",
    "\n",
    "    Args:\n",
    "    - G: a networkx Graph object representing the graph\n",
    "    - start_point_id: the ID of the node where the path starts\n",
    "    - end_point_id: the ID of the node where the path ends\n",
    "    - weight: the attribute used to determine the weight of the edges in the graph (default: \"weight\")\n",
    "\n",
    "    Returns:\n",
    "    - a tuple containing:\n",
    "        - the list of nodes that form the shortest path from start_point_id to end_point_id\n",
    "        - the length of the shortest path\n",
    "        - a pandas DataFrame containing the edges that belong to the shortest path, with a new column 'linewidth' that is proportional to the edge dis_weights\n",
    "\n",
    "    Example:\n",
    "    >>> import networkx as nx\n",
    "    >>> import pandas as pd\n",
    "    >>> G = nx.Graph()\n",
    "    >>> G.add_edge(0, 1, weight=2.0)\n",
    "    >>> G.add_edge(1, 2, weight=1.0)\n",
    "    >>> G.add_edge(0, 2, weight=3.0)\n",
    "    >>> path, length, edges = shortest_path(G, 0, 2)\n",
    "    >>> print(path)\n",
    "    [0, 1, 2]\n",
    "    >>> print(length)\n",
    "    3.0\n",
    "    >>> print(edges)\n",
    "       from_id  to_id  dis_weights  to_from  from_to  linewidth\n",
    "    0        0      1      2.0      NaN      1.0        1.0\n",
    "    2        1      2      1.0      2.0      NaN        1.0\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compute the shortest path and its length using the networkx library\n",
    "    path_s_e = nx.shortest_path(G, source=start_point_id, target=end_point_id, weight= weight)\n",
    "    length_s_e = nx.shortest_path_length(G, source=start_point_id, target=end_point_id, weight= weight)\n",
    "    \n",
    "   \n",
    "    # Select the edges that belong to the shortest path and compute their linewidth based on their weight\n",
    "    short_path_edges = edges.loc[edges.to_from.isin(list(pairwise(path_s_e))) | edges.from_to.isin(list(pairwise(path_s_e)))]\n",
    "    #short_path_edges['linewidth'] = short_path_edges['dis_weights'].apply(lambda x: np.ceil(x * 0.01 / 2))   # test 'linewidth' with one pair and there is no practical significance camparing with several routes and can be left out of the calculation \n",
    "    \n",
    "    # Return the computed values as a tuple\n",
    "    return path_s_e, length_s_e, short_path_edges\n",
    "\n",
    "\n",
    "def all_shortest_paths(id_pairs,edges):\n",
    "    \"\"\"\n",
    "    Find all shortest paths between start and end nodes and extract corresponding edges.\n",
    "\n",
    "    Args:\n",
    "    - id_pairs: a pandas DataFrame containing start and end node IDs for each path\n",
    "    - edges: a pandas DataFrame containing edges in the network, with columns 'from_id', 'to_id', and 'dis_weights'\n",
    "\n",
    "    Returns:\n",
    "    - shortest_path_pairs: a pandas DataFrame containing the edges for all shortest paths found\n",
    "\n",
    "    Example:\n",
    "    >>> shortest_path_pairs = all_shortest_paths(id_pairs, edges)\n",
    "\n",
    "    Note: This function requires the pandas and networkx libraries to be installed.\n",
    "    \"\"\"\n",
    "    row_num = id_pairs.shape[0]\n",
    "    shortest_path_pairs = pd.DataFrame()\n",
    "    \n",
    "    for i in range(row_num):\n",
    "        s_id = id_pairs.loc[i,'s_id']\n",
    "        e_id = id_pairs.loc[i,'e_id']\n",
    "        try:\n",
    "            # Find shortest path between start and end nodes\n",
    "            path_s_e = nx.shortest_path(G, source=s_id, target=e_id, weight= \"weight\")\n",
    "            # Extract edges corresponding to shortest path\n",
    "            short_path_edges = edges.loc[edges.to_from.isin(list(pairwise(path_s_e))) | edges.from_to.isin(list(pairwise(path_s_e)))]\n",
    "            shortest_path_pairs = pd.concat([shortest_path_pairs,short_path_edges])\n",
    "        except nx.NetworkXNoPath:\n",
    "            # If no path exists between start and end nodes, continue to next pair\n",
    "            # print(f\"No path found between {s_id} and {e_id}\")\n",
    "            continue\n",
    "        #print(path_s_e, length_s_e)\n",
    "        \n",
    "    return shortest_path_pairs\n",
    "\n",
    "\n",
    "# calculates the number of repetitions of each used edge and add the number to 'edges' with column of 'count_weight'\n",
    "def edges_with_count_weight(shortest_path_pairs, edges):\n",
    "    \"\"\"\n",
    "    Adds a 'count_weight' column to the edges dataframe to represent the number of times \n",
    "    each edge was used in the shortest paths. \n",
    "    Args:\n",
    "        shortest_path_pairs (pandas.DataFrame): A DataFrame containing the edges that \n",
    "            are used in the shortest paths.\n",
    "        edges (pandas.DataFrame): A DataFrame containing all the edges in the graph.\n",
    "    Returns:\n",
    "        A tuple of two DataFrames: \n",
    "            - shortest_path_edges (pandas.DataFrame): A DataFrame containing only the edges \n",
    "              used in the shortest paths and their corresponding 'count_weight' value.\n",
    "            - edges (pandas.DataFrame): A DataFrame containing all the edges in the graph \n",
    "              and their corresponding 'count_weight' value.\n",
    "    \"\"\"\n",
    "    shortest_path_edges = pd.DataFrame()\n",
    "    shortest_path_pairs_duplicate_count = pd.DataFrame()\n",
    "    \n",
    "    # Copy the id of the edges that are used in the shortest paths to a new DataFrame\n",
    "    shortest_path_pairs_duplicate_count['id'] = shortest_path_pairs['id']\n",
    "    \n",
    "    # Count the number of times each edge is used in the shortest paths\n",
    "    duplicate_row_count = pd.DataFrame(shortest_path_pairs_duplicate_count[shortest_path_pairs_duplicate_count['id'].duplicated(keep=False)].value_counts(dropna=False))\n",
    "    duplicate_row_count = duplicate_row_count.reset_index()\n",
    "    duplicate_row_count.columns = ['id','count_weight']\n",
    "    \n",
    "    # Merge the 'count_weight' values with the original edges DataFrame\n",
    "    edges = pd.merge(edges, duplicate_row_count, on='id', how='left')\n",
    "    edges['count_weight'] = edges['count_weight'].fillna(1)\n",
    "    # Merge the 'count_weight' values with the edges used in the shortest paths DataFrame\n",
    "    shortest_path_edges = pd.merge(shortest_path_pairs,duplicate_row_count, on='id', how='left')\n",
    "    shortest_path_edges['count_weight'] = shortest_path_edges['count_weight'].fillna(1)\n",
    "    return duplicate_row_count, shortest_path_edges, edges\n",
    "\n",
    "\n",
    "# Calculate maximum flow for each route and draw each of them with linewidth of 'capacity'\n",
    "def max_flow (edges, nodes, route_capacity, id_pairs, G):\n",
    "    \"\"\"\n",
    "    Calculate the maximum flow through a network, given the edges and nodes information of the network, the capacity of the routes, the start and end node pairs, and the Graph object G.\n",
    "    Args:\n",
    "        edges (pandas.DataFrame): A DataFrame containing information about the edges of the network, including the from_id, to_id, and capacity of each edge.\n",
    "        nodes (pandas.DataFrame): A DataFrame containing information about the nodes of the network.\n",
    "        route_capacity (pandas.Series): A Series containing the capacity of each route in the network.\n",
    "        id_pairs (pandas.DataFrame): A DataFrame containing the start and end node pairs of each route in the network.\n",
    "        G (networkx.classes.graph.Graph): The Graph object representing the network.\n",
    "    Returns:\n",
    "        edges: A pandas DataFrame that contains information about edges in a graph, including the from_id, to_id, weight, and capacity columns.\n",
    "        route_edges: A pandas DataFrame that contains information about edges on the shortest path between source and target node pairs, including the from_id, to_id, weight, and capacity columns.\n",
    "        flow_value_dict: A pandas DataFrame that contains information about flow values between source and target node pairs, including the source, target, and flow columns.\n",
    "        flow_value: A float value that represents the maximum flow value in the graph.\n",
    "\n",
    "    The function adds the capacity of each route to the corresponding edges of the network. Then, it creates a new networkx Graph object, G_max, based on the updated edge capacity information. Afterward, it calculates the maximum flow through G_max using the networkx maximum_flow function.\n",
    "    \"\"\"\n",
    "    edges['capacity'] = 0\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3,figsize=(15,7))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < 5:\n",
    "            route, route_weight, route_edges = shortest_path(G, id_pairs.loc[i, 's_id'], id_pairs.loc[i, 'e_id'], edges, weight = \"weight\")\n",
    "            route_edges['capacity'] = 0\n",
    "            route_edges['capacity'] = route_capacity.metro_num[i]\n",
    "            #print(route_edges)\n",
    "            common_edges = set(route_edges['to_from']).intersection(set(edges['to_from'])) \\\n",
    "                    .union(set(route_edges['from_to']).intersection(set(edges['from_to'])))\n",
    "            edges.loc[edges['to_from'].isin(common_edges) | edges['from_to'].isin(common_edges), 'capacity'] = edges['capacity'] + route_capacity.metro_num[i]\n",
    "            #print(edges)\n",
    "        if i == 0:\n",
    "            gpd.GeoDataFrame(edges.copy()).plot(ax=ax, color='gray', alpha=0.5)\n",
    "            gpd.GeoDataFrame(route_edges.copy()).plot(ax=ax, color='red', linewidth=route_edges['capacity'])\n",
    "            ax.set_title('Route 0')\n",
    "        elif i == 1:\n",
    "            gpd.GeoDataFrame(edges.copy()).plot(ax=ax, color='gray', alpha=0.5)\n",
    "            gpd.GeoDataFrame(route_edges.copy()).plot(ax=ax, color='green', linewidth=route_edges['capacity'])        \n",
    "            ax.set_title('Route 1')\n",
    "        elif i == 2:\n",
    "            gpd.GeoDataFrame(edges.copy()).plot(ax=ax, color='gray', alpha=0.5)\n",
    "            gpd.GeoDataFrame(route_edges.copy()).plot(ax=ax, color='blue', linewidth=route_edges['capacity'])\n",
    "            ax.set_title('Route 2')\n",
    "        elif i ==3:\n",
    "            gpd.GeoDataFrame(edges.copy()).plot(ax=ax, color='gray', alpha=0.5)\n",
    "            gpd.GeoDataFrame(route_edges.copy()).plot(ax=ax, color='orange', linewidth=route_edges['capacity'])\n",
    "            ax.set_title('Route 3')\n",
    "        elif i ==4:\n",
    "            gpd.GeoDataFrame(edges.copy()).plot(ax=ax, color='gray', alpha=0.5)\n",
    "            gpd.GeoDataFrame(route_edges.copy()).plot(ax=ax, color='pink', linewidth=route_edges['capacity'])\n",
    "            ax.set_title('Route 4')\n",
    "        else:    \n",
    "            ax.axis('off')\n",
    "    \n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    od = edges[['from_id', 'to_id', 'capacity']]\n",
    "    edges_list = []\n",
    "    for i, row in od.iterrows():\n",
    "        capacity_dict = {\"capacity\": row[2]}\n",
    "        tuple_row = (row[0], row[1], capacity_dict)\n",
    "        edges_list.append(tuple_row)\n",
    "    #edges_list\n",
    "    nodes_list = nodes.iloc[:,2].tolist()\n",
    "    G_max = nx.Graph()\n",
    "    G_max.add_nodes_from(nodes_list)\n",
    "    G_max.add_edges_from(edges_list)\n",
    "    \n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < 5:\n",
    "            flow_value, flow_dict = nx.maximum_flow(G_max, id_pairs.loc[i, 's_id'], id_pairs.loc[i, 'e_id'])\n",
    "            flow_value_dict = pd.DataFrame(columns=[\"source\", \"target\", \"flow\"])\n",
    "            for source, targets in flow_dict.items():\n",
    "                for target, flow in targets.items():\n",
    "                    flow_value_dict = flow_value_dict.append({\"source\":source, \"target\":target, \"flow\":flow}, ignore_index=True)\n",
    "            print(flow_value_dict)\n",
    "            print(\"Maximum flow:\", flow_value)\n",
    "    \n",
    "    return edges, route_edges, flow_value_dict, flow_value\n",
    "\n",
    "\n",
    "# Creat the dataset of 'edges' after delete some edges randomly\n",
    "def missing_edges(edges, e_num):\n",
    "    missing_edges = random.sample(list(edges.index), e_num)\n",
    "    edges = edges.drop(missing_edges)\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b650b1-dd4e-4274-825e-03bcb22d9c0e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Test all routes of Amsterdam subway/metro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d7c3b6-f192-4fb4-be56-bbd8b5df0268",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step1: get data of edges and nodes from OSM map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf8da56-9d8e-4ce6-b5f5-eb7e37e87c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "osm_path = \"C:\\\\projects\\\\UTNCE\\\\data\\\\Amsterdam.osm.pbf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8c9e1d-2286-453d-997a-cc32d6e47605",
   "metadata": {},
   "outputs": [],
   "source": [
    "subway = subway_network(osm_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c2bd9f-cb05-4ddb-8479-c5c467d19741",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges,nodes = prepare_network(subway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d646fdbf-27c2-4aee-bc27-f18a344c2b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = expand_edges(edges)\n",
    "edges\n",
    "# nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca38600a-68de-4ac7-b771-54967a6e4e97",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step2: read pair data of coordinates of 5 amsterdam subway stations and calculate the id pairs of stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc11293-94cc-4ba9-a76b-7058a0d1d07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "am_sub_coordinates = pd.read_excel(r'./am_sub_coordinates_pairs.xlsx')\n",
    "#am_sub_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65d890a-38d0-49af-861e-ef2455de4ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "am_sub_coordinates_pairs = pd.DataFrame()\n",
    "am_sub_coordinates_pairs['s_coordinates'] = list(zip(am_sub_coordinates.s_coordinates_x, am_sub_coordinates.s_coordinates_y))\n",
    "am_sub_coordinates_pairs['e_coordinates'] = list(zip(am_sub_coordinates.e_coordinates_x, am_sub_coordinates.e_coordinates_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc55414f-5750-4a6d-ad84-ae5237691930",
   "metadata": {},
   "outputs": [],
   "source": [
    "am_sub_id_pairs = id_pairs(am_sub_coordinates_pairs,nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaafc55-6ede-467c-9ed8-8cadff869e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "am_sub_id_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dbbcac-2409-4172-b1ff-1d9a9c0e932f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step3: calculate shortest pathes for all id pairs and visulize the subway map with the used time of each edges "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0ce687-d1d5-46b2-a0a5-7091ead4da07",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = create_ground_graph(edges, nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3339a2a8-4b8e-4663-bca4-d057c6f5f1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "am_sub_shortest_path_pairs = all_shortest_paths(am_sub_id_pairs,edges)\n",
    "am_sub_shortest_path_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000769eb-66eb-4007-9007-1bfb6550a6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# am_sub_shortest_path_pairs.to_excel('./am_sub_shortest_path_pairs.xlsx',header = True, index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51a19ce-bd7a-48d3-9b11-ecfd98927969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1, 1,figsize=(12,10))\n",
    "\n",
    "# gpd.GeoDataFrame(am_sub_shortest_path_pairs.copy()).plot(ax=ax,zorder=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a69506-f5be-4e2c-8ef0-251768fe50ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_row_count, am_sub_shortest_path_edges, edges = edges_with_count_weight(am_sub_shortest_path_pairs,edges)\n",
    "#am_sub_shortest_path_edges, duplicate_row_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb65a21-485e-4dde-a121-9c5adc48adca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# am_sub_shortest_path_edges.to_excel('./am_sub_shortest_path_edges.xlsx',header = True, index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795676bf-4025-475f-9e00-695f3dd1e35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1,figsize=(12,10))\n",
    "\n",
    "gpd.GeoDataFrame(edges.copy()).plot(ax=ax,zorder=0)\n",
    "gpd.GeoDataFrame(am_sub_shortest_path_edges.copy()).plot(ax=ax,color='black',zorder=1,linewidth=(am_sub_shortest_path_edges['count_weight'])*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db3753e-0a3e-48e1-8326-fb6e3d865451",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1,figsize=(12,10))\n",
    "\n",
    "gpd.GeoDataFrame(edges.copy()).plot(ax=ax,zorder=0)\n",
    "gpd.GeoDataFrame(edges.copy()).plot(ax=ax,color='black',zorder=1,linewidth=(edges['count_weight'])*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755660d9-ab89-4b8d-8deb-1c509c4d33e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step4: draw each route with the base map of Amsterdam subway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d9bc5f-fae2-4366-813c-08f47fda0317",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3,figsize=(15,7))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < 5:\n",
    "        route, route_weight, route_edges = shortest_path(G, am_sub_id_pairs.loc[i, 's_id'], am_sub_id_pairs.loc[i, 'e_id'], edges, weight = \"dis_weights\")\n",
    "    \n",
    "    if i == 0:\n",
    "        gpd.GeoDataFrame(edges.copy()).plot(ax=ax, color='gray', alpha=0.5)\n",
    "        gpd.GeoDataFrame(route_edges.copy()).plot(ax=ax, color='red')\n",
    "        ax.set_title('Route 0')\n",
    "    elif i == 1:\n",
    "        gpd.GeoDataFrame(edges.copy()).plot(ax=ax, color='gray', alpha=0.5)\n",
    "        gpd.GeoDataFrame(route_edges.copy()).plot(ax=ax, color='green')        \n",
    "        ax.set_title('Route 1')\n",
    "    elif i == 2:\n",
    "        gpd.GeoDataFrame(edges.copy()).plot(ax=ax, color='gray', alpha=0.5)\n",
    "        gpd.GeoDataFrame(route_edges.copy()).plot(ax=ax, color='blue')\n",
    "        ax.set_title('Route 2')\n",
    "    elif i ==3:\n",
    "        gpd.GeoDataFrame(edges.copy()).plot(ax=ax, color='gray', alpha=0.5)\n",
    "        gpd.GeoDataFrame(route_edges.copy()).plot(ax=ax, color='orange')\n",
    "        ax.set_title('Route 3')\n",
    "    elif i ==4:\n",
    "        gpd.GeoDataFrame(edges.copy()).plot(ax=ax, color='gray', alpha=0.5)\n",
    "        gpd.GeoDataFrame(route_edges.copy()).plot(ax=ax, color='pink')\n",
    "        ax.set_title('Route 4')\n",
    "    else:    \n",
    "        ax.axis('off')\n",
    "    \n",
    "    ax.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1abf46-c60b-4e99-92bb-5debc1079769",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step5: calculate maximum flow for each route of Amsterdam subway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0454937e-48f9-4d6a-aa10-2dbb42783786",
   "metadata": {},
   "outputs": [],
   "source": [
    "route_capacity = pd.DataFrame({'metro_num': [5.0, 4.0, 7.0, 6.0, 8.0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06616f5-669a-43bc-bc3b-f72639b65202",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges, route_edges, flow_value_dict, flow_value = max_flow(edges, nodes, route_capacity, am_sub_id_pairs, G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df9b23b-f2c7-460d-9430-36d30e355546",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff641f0-f860-419e-ac4e-8e4865d0562a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa165751-5115-44bb-8c6b-9b84f99dc03a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcc3b39-24d9-417a-a61b-87e2faebd53b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fde58f5f-f082-43d6-96fd-b3daefd7a07f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Old test records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7a1f8b-8158-4f32-9649-3c9c4bd7683d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## try to define capacity with each route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22497a4d-422b-4a08-9781-ddbe8a798f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "route_capacity = pd.DataFrame({'metro_num': [2.0, 6.0, 7.0, 3.0, 8.0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629f88cc-314e-471b-91d1-a922ec62d262",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges['capacity'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c672db-d23b-4f4c-b5f0-238b5a75106b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3,figsize=(15,7))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < 5:\n",
    "        route, route_weight, route_edges = shortest_path(G, am_sub_id_pairs.loc[i, 's_id'], am_sub_id_pairs.loc[i, 'e_id'], edges, weight = \"weight\")\n",
    "        route_edges['capacity'] = 0\n",
    "        route_edges['capacity'] = route_capacity.metro_num[i]\n",
    "        #print(route_edges)\n",
    "        common_edges = set(route_edges['to_from']).intersection(set(edges['to_from'])) \\\n",
    "                .union(set(route_edges['from_to']).intersection(set(edges['from_to'])))\n",
    "        edges.loc[edges['to_from'].isin(common_edges) | edges['from_to'].isin(common_edges), 'capacity'] = edges['capacity'] + route_capacity.metro_num[i]\n",
    "        #print(edges)\n",
    "    \n",
    "    if i == 0:\n",
    "        gpd.GeoDataFrame(edges.copy()).plot(ax=ax, color='gray', alpha=0.5)\n",
    "        gpd.GeoDataFrame(route_edges.copy()).plot(ax=ax, color='red', linewidth=route_edges['capacity'])\n",
    "        ax.set_title('Route 0')\n",
    "    elif i == 1:\n",
    "        gpd.GeoDataFrame(edges.copy()).plot(ax=ax, color='gray', alpha=0.5)\n",
    "        gpd.GeoDataFrame(route_edges.copy()).plot(ax=ax, color='green', linewidth=route_edges['capacity'])        \n",
    "        ax.set_title('Route 1')\n",
    "    elif i == 2:\n",
    "        gpd.GeoDataFrame(edges.copy()).plot(ax=ax, color='gray', alpha=0.5)\n",
    "        gpd.GeoDataFrame(route_edges.copy()).plot(ax=ax, color='blue', linewidth=route_edges['capacity'])\n",
    "        ax.set_title('Route 2')\n",
    "    elif i ==3:\n",
    "        gpd.GeoDataFrame(edges.copy()).plot(ax=ax, color='gray', alpha=0.5)\n",
    "        gpd.GeoDataFrame(route_edges.copy()).plot(ax=ax, color='orange', linewidth=route_edges['capacity'])\n",
    "        ax.set_title('Route 3')\n",
    "    elif i ==4:\n",
    "        gpd.GeoDataFrame(edges.copy()).plot(ax=ax, color='gray', alpha=0.5)\n",
    "        gpd.GeoDataFrame(route_edges.copy()).plot(ax=ax, color='pink', linewidth=route_edges['capacity'])\n",
    "        ax.set_title('Route 4')\n",
    "    else:    \n",
    "        ax.axis('off')\n",
    "    \n",
    "    ax.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dcddbb-cd91-4fbe-8203-63bd1b39e681",
   "metadata": {},
   "outputs": [],
   "source": [
    "od = edges[['from_id', 'to_id', 'capacity']]\n",
    "edges_list = []\n",
    "for i, row in od.iterrows():\n",
    "    capacity_dict = {\"capacity\": row[2]}\n",
    "    tuple_row = (row[0], row[1], capacity_dict)\n",
    "    edges_list.append(tuple_row)\n",
    "#edges_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ce1425-0169-4a19-bb91-772b69e06ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the nodes from the input GeoDataFrame and create a list of node IDs\n",
    "nodes_list = nodes.iloc[:,2].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e6de69-6925-452d-b83c-9a0b2939fb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty Graph object and add the nodes and edges\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(nodes_list)\n",
    "G.add_edges_from(edges_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e7a735-2bcc-402a-ac1c-513061c2dcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < 5:\n",
    "        flow_value, flow_dict = nx.maximum_flow(G, am_sub_id_pairs.loc[i, 's_id'], am_sub_id_pairs.loc[i, 'e_id'])\n",
    "        flow_value_dict = pd.DataFrame(columns=[\"source\", \"target\", \"flow\"])\n",
    "        for source, targets in flow_dict.items():\n",
    "            for target, flow in targets.items():\n",
    "                flow_value_dict = flow_value_dict.append({\"source\":source, \"target\":target, \"flow\":flow}, ignore_index=True)\n",
    "        print(flow_value_dict)\n",
    "        print(\"Maximum flow:\", flow_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc63c5a-506c-4f5d-974a-d1b197697f1f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## try to define capacity with count_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f12f1e-b036-4f02-9b99-2fd0ae3220b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges['capacity'] = (edges['count_weight']*2).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b250310-33de-4efc-aed8-64a6dc488701",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f08fe6f-ff62-419e-ba44-a3af0fd59b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "od = edges[['from_id', 'to_id', 'capacity']]\n",
    "edges_list = []\n",
    "for i, row in od.iterrows():\n",
    "    capacity_dict = {\"capacity\": row[2]}\n",
    "    tuple_row = (row[0], row[1], capacity_dict)\n",
    "    edges_list.append(tuple_row)\n",
    "#edges_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf381b6-aa64-4c54-a06b-32ab3157b075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the nodes from the input GeoDataFrame and create a list of node IDs\n",
    "nodes_list = nodes.iloc[:,2].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01448949-5c3f-4f97-946f-474f128a3a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty Graph object and add the nodes and edges\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(nodes_list)\n",
    "G.add_edges_from(edges_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4cf7c1-d2f2-4aeb-b6a5-5658e85e2d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < 5:\n",
    "        flow_value, flow_dict = nx.maximum_flow(G, am_sub_id_pairs.loc[i, 's_id'], am_sub_id_pairs.loc[i, 'e_id'])\n",
    "        flow_value_dict = pd.DataFrame(columns=[\"source\", \"target\", \"flow\"])\n",
    "        for source, targets in flow_dict.items():\n",
    "            for target, flow in targets.items():\n",
    "                flow_value_dict = flow_value_dict.append({\"source\":source, \"target\":target, \"flow\":flow}, ignore_index=True)\n",
    "        print(flow_value_dict)\n",
    "        print(\"Maximum flow:\", flow_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2145bc-c007-4d75-8a98-d290f8c11382",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    if i < 5:\n",
    "        flow_value, flow_dict = nx.maximum_flow(G, am_sub_id_pairs.loc[i, 's_id'], am_sub_id_pairs.loc[i, 'e_id'])\n",
    "        flow_value_dict = pd.DataFrame(columns=[\"source\", \"target\", \"flow\"])\n",
    "        for source, targets in flow_dict.items():\n",
    "            for target, flow in targets.items():\n",
    "                flow_value_dict = flow_value_dict.append({\"source\":source, \"target\":target, \"flow\":flow}, ignore_index=True)\n",
    "        print(flow_value_dict)\n",
    "        print(\"Maximum flow:\", flow_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ce5f86-8d89-48f2-a622-40ca9813c60f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## try minimum cost flow--should be a directed graph at first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83df2556-ca95-40af-84c0-a24890f5a9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "od = edges[['from_id', 'to_id', 'dis_weights', 'capacity']]\n",
    "edges_list = []\n",
    "for i, row in od.iterrows():\n",
    "    weight_dict = {\"weight\": row[2]}\n",
    "    capacity_dict = {\"capacity\": row[3]}\n",
    "    tuple_row = (row[0], row[1], weight_dict, capacity_dict)\n",
    "    edges_list.append(tuple_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901360ab-031b-4ff9-b3bc-32ad6baa760e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the nodes from the input GeoDataFrame and create a list of node IDs\n",
    "nodes_list = nodes.iloc[:,2].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e470d8bc-b08a-490b-bb11-97dd893e0927",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "G.add_nodes_from(nodes_list)\n",
    "for edge in edges_list:\n",
    "    G.add_edge(edge[0], edge[1], capacity=edge[2], weight=edge[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2818c98f-8fb3-463f-aace-bc9328a816a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < 5:\n",
    "        flowDict = nx.min_cost_flow(G)\n",
    "        print(\"Flow: \", flowDict)\n",
    "        print(\"Cost: \", nx.cost_of_flow(G, flowDict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b374add5-67a8-49c8-873d-1c05d671ef20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5862b6-3547-47a8-963c-478eb8bfcc58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6964fbe0-2ee7-443c-bde4-bca81dd628a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50db7880-f606-4d67-b9bc-ae0a9f1763df",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dummy data test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3c723b-8322-47b3-a2be-0c1ef0604055",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "osm_path = \"C:\\\\projects\\\\UTNCE\\\\data\\\\Amsterdam.osm.pbf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709b0db3-f71c-4e0e-be45-8df5a80f7a60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "subway = subway_network(osm_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c075af-f2db-41a6-a167-18113dab3b7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# subway.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6651259-ad43-4d94-b29d-beb18a6a7411",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "edges,nodes = prepare_network(subway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88abfc7-9d7e-444d-bc4c-06d00261c392",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "edges = expand_edges(edges)\n",
    "# edges\n",
    "# nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14b8266-d51c-4571-a521-342499fb5172",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = pd.DataFrame(create_grid(edges.geometry,0.01),columns=['geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a834895-4f7f-43cb-8f21-96cee44caf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates_pairs = coordinates_pairs(grid)\n",
    "coordinates_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60c30f5-8ceb-4cf9-86cd-5110702c636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coordinates_pairs.to_excel('./coordinates_pairs.xlsx',header = True, index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ff6b74-cf22-4525-be36-77b238f0bc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_pairs = id_pairs(coordinates_pairs,nodes)\n",
    "id_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6a7e1f-8956-4359-a961-dd3f9d1b8a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_pairs.to_excel('./id_pairs.xlsx',header = True, index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098e1aae-f9fe-4aab-8071-6da2107d4075",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "G = create_ground_graph(edges, nodes)\n",
    "# G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5723b675-e71d-4174-8c66-75b3f165b275",
   "metadata": {},
   "outputs": [],
   "source": [
    "shortest_path_pairs = all_shortest_paths(id_pairs,edges)\n",
    "shortest_path_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b0df24-00ea-4f48-b2ea-a8adfa873caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "shortest_path_edges,edges = edges_with_count_weight(shortest_path_pairs,edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642ece95-6178-4643-9227-3b19be4109a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "shortest_path_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9d5ad8-0549-4126-adef-e9b152460fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e813fa-363e-4e78-bbfc-ea6885f651ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1,figsize=(12,10))\n",
    "\n",
    "gpd.GeoDataFrame(edges.copy()).plot(ax=ax,zorder=0)\n",
    "gpd.GeoDataFrame(edges.copy()).plot(ax=ax,color='black',zorder=1,linewidth=(edges['count_weight'])/500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6942da49-492f-431d-b32f-92d46b02947c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1,figsize=(12,10))\n",
    "\n",
    "gpd.GeoDataFrame(edges.copy()).plot(ax=ax,zorder=0)\n",
    "gpd.GeoDataFrame(shortest_path_edges.copy()).plot(ax=ax,color='black',zorder=1,linewidth=(shortest_path_edges['count_weight'])/500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398096c4-187c-46b3-8a94-3e2c1f9dd596",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c015c784-5ee3-4ce2-93a3-28f653784872",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd6ed5a-5712-4ced-aaa4-1f015c7c2e98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da8d696-706d-4f8e-8131-09b4d0e233b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpd.GeoDataFrame(grid.copy()).plot(edgecolor='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25b6b24-6d0a-415a-b253-7772911d4723",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpd.GeoDataFrame(pygeos.centroid(grid.geometry.values),columns=['geometry']).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fd85ba-3d8c-4bac-964b-f41965b04c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpd.GeoDataFrame(grid_center_coordinates).plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
